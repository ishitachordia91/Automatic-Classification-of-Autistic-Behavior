README: 
There are four parts of this: loadData, labelData, featureExtraction, classification. The main file is Goodwin_ReproduceResults.py


Look at stereotypyMain.m to see how Goodwin did it- we need to follow it exactly
preprocessedDataAndLabels is exactly the same as Goodwin. When I start back up, start with featureExtraction

Steps To Do Next:
1. You load the Hd.mat in python and use it to filter the preprocessedData
2. Figure out how to do Stockwell transform
3. Classify then using what they did + Neural nets
When I start back up, you can run matlab code by going on https://mycloud.gatech.edu/Citrix/GTMyCloudWeb/
Documentation: https://docs.google.com/document/d/12cjQ6QPVeTjPgOZZtoWGJ0Wqh9KEk20LOLi3qEW17D4/edit#
How accelerometer data works: http://stackoverflow.com/questions/5871429/accelerometer-data-how-to-interpret
